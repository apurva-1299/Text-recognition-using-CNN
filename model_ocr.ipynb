{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as k\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense,Dropout,Activation\n",
    "from keras.optimizers import Adam\n",
    "#from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "import argparse\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "#from pyimagesearch.stridednet import StridedNet\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img):\n",
    "    img = cv2.resize(img,(20,20))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# to get the name of the folder\n",
    "for name_folder in os.listdir(\"C:\\\\Users\\HP\\Desktop\\optical-character-recognition-OCR-master\\Fnt\") :\n",
    "\n",
    "    name = 'C:\\\\Users\\HP\\Desktop\\optical-character-recognition-OCR-master\\Fnt/' + name_folder\n",
    "    for f in listdir(name):\n",
    "        # name of the folder is the name of the output\n",
    "        y_train.append(np.asarray(name_folder))\n",
    "        \n",
    "        # constructing full path to the image\n",
    "        name = 'C:\\\\Users\\HP\\Desktop\\optical-character-recognition-OCR-master\\Fnt/' + name_folder + '/' + f\n",
    "        \n",
    "        # reading the image\n",
    "        image = cv2.imread(name,0)/255\n",
    "        \n",
    "        # appending to form the image list\n",
    "        image = np.asarray(image)\n",
    "        image = resize(image)\n",
    "        X_train.append([image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36576, 1, 20, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, [-1,20,20,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36576, 20, 20, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y_train = onehot_encoder.fit_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StridedNet:\n",
    "    def build(width, height, depth,reg, init=\"he_normal\"):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            \n",
    "# our first CONV layer will learn a total of 16 filters, each\n",
    "\t\t# Of which are 7x7 -- we'll then apply 2x2 strides to reduce\n",
    "\t\t# the spatial dimensions of the volume\n",
    "        model.add(Conv2D(16, (7, 7), strides=(2, 2), padding=\"valid\",\n",
    "            kernel_initializer=init, kernel_regularizer=reg,\n",
    "            input_shape=inputShape))\n",
    "        \n",
    "\t\t# here we stack two CONV layers on top of each other where\n",
    "\t\t# each layerswill learn a total of 32 (3x3) filters\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "            kernel_initializer=init, kernel_regularizer=reg))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\",\n",
    "            kernel_initializer=init, kernel_regularizer=reg))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # stack two more CONV layers, keeping the size of each filter\n",
    "\t\t# as 3x3 but increasing to 64 total learned filters\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\",\n",
    "            kernel_initializer=init, kernel_regularizer=reg))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\",\n",
    "            kernel_initializer=init, kernel_regularizer=reg))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "\t\t# increase the number of filters again, this time to 128\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\",\n",
    "            kernel_initializer=init, kernel_regularizer=reg))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\",\n",
    "            kernel_initializer=init, kernel_regularizer=reg))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # fully-connected layer\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, kernel_initializer=init))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "\t\t# softmax classifier\n",
    "        model.add(Dense(36, activation=\"softmax\"))\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "#opt = Adam(lr=1e-4, decay=1e-4 / args[50])\n",
    "model = StridedNet.build(width=20, height=20, depth=1,reg=l2(0.0005))\n",
    "#model=StridedNet()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 16)          800       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 1, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 36)                18468     \n",
      "=================================================================\n",
      "Total params: 379,908\n",
      "Trainable params: 377,988\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train,y_train ,test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29260, 20, 20, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7316, 20, 20, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29260, 36)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29260\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "97/97 [==============================] - 38s 396ms/step - loss: 4.7930 - accuracy: 0.0440 - val_loss: 3.8703 - val_accuracy: 0.0428\n",
      "Epoch 2/50\n",
      "97/97 [==============================] - 38s 395ms/step - loss: 4.0529 - accuracy: 0.0774 - val_loss: 3.3223 - val_accuracy: 0.1588\n",
      "Epoch 3/50\n",
      "97/97 [==============================] - 37s 380ms/step - loss: 3.5389 - accuracy: 0.1368 - val_loss: 3.1382 - val_accuracy: 0.2276\n",
      "Epoch 4/50\n",
      "97/97 [==============================] - 38s 396ms/step - loss: 3.1535 - accuracy: 0.1972 - val_loss: 2.5913 - val_accuracy: 0.3252\n",
      "Epoch 5/50\n",
      "97/97 [==============================] - 29s 295ms/step - loss: 2.8634 - accuracy: 0.2552 - val_loss: 2.2502 - val_accuracy: 0.4258\n",
      "Epoch 6/50\n",
      "97/97 [==============================] - 28s 292ms/step - loss: 2.6218 - accuracy: 0.3186 - val_loss: 2.0474 - val_accuracy: 0.4993\n",
      "Epoch 7/50\n",
      "97/97 [==============================] - 28s 285ms/step - loss: 2.4195 - accuracy: 0.3681 - val_loss: 1.9072 - val_accuracy: 0.5252\n",
      "Epoch 8/50\n",
      "97/97 [==============================] - 28s 292ms/step - loss: 2.2362 - accuracy: 0.4148 - val_loss: 1.7274 - val_accuracy: 0.5815\n",
      "Epoch 9/50\n",
      "97/97 [==============================] - 29s 301ms/step - loss: 2.0993 - accuracy: 0.4532 - val_loss: 1.3804 - val_accuracy: 0.6720\n",
      "Epoch 10/50\n",
      "97/97 [==============================] - 29s 295ms/step - loss: 1.9860 - accuracy: 0.4863 - val_loss: 1.4046 - val_accuracy: 0.6648\n",
      "Epoch 11/50\n",
      "97/97 [==============================] - 29s 296ms/step - loss: 1.8834 - accuracy: 0.5164 - val_loss: 1.3161 - val_accuracy: 0.6848\n",
      "Epoch 12/50\n",
      "97/97 [==============================] - 31s 321ms/step - loss: 1.7739 - accuracy: 0.5460 - val_loss: 1.3159 - val_accuracy: 0.6875\n",
      "Epoch 13/50\n",
      "97/97 [==============================] - 31s 318ms/step - loss: 1.7258 - accuracy: 0.5617 - val_loss: 1.1637 - val_accuracy: 0.7324\n",
      "Epoch 14/50\n",
      "97/97 [==============================] - 33s 342ms/step - loss: 1.6367 - accuracy: 0.5868 - val_loss: 1.0979 - val_accuracy: 0.7669\n",
      "Epoch 15/50\n",
      "97/97 [==============================] - 34s 348ms/step - loss: 1.5869 - accuracy: 0.5988 - val_loss: 1.0763 - val_accuracy: 0.7652\n",
      "Epoch 16/50\n",
      "97/97 [==============================] - 30s 305ms/step - loss: 1.5252 - accuracy: 0.6157 - val_loss: 0.9655 - val_accuracy: 0.7918\n",
      "Epoch 17/50\n",
      "97/97 [==============================] - 32s 328ms/step - loss: 1.4664 - accuracy: 0.6355 - val_loss: 0.9809 - val_accuracy: 0.7898\n",
      "Epoch 18/50\n",
      "97/97 [==============================] - 34s 351ms/step - loss: 1.4329 - accuracy: 0.6432 - val_loss: 0.8901 - val_accuracy: 0.8189\n",
      "Epoch 19/50\n",
      "97/97 [==============================] - 35s 363ms/step - loss: 1.3838 - accuracy: 0.6579 - val_loss: 0.9143 - val_accuracy: 0.8084\n",
      "Epoch 20/50\n",
      "97/97 [==============================] - 30s 311ms/step - loss: 1.3378 - accuracy: 0.6711 - val_loss: 0.8298 - val_accuracy: 0.8283\n",
      "Epoch 21/50\n",
      "97/97 [==============================] - 32s 330ms/step - loss: 1.3125 - accuracy: 0.6780 - val_loss: 0.8038 - val_accuracy: 0.8354\n",
      "Epoch 22/50\n",
      "97/97 [==============================] - 32s 329ms/step - loss: 1.2878 - accuracy: 0.6872 - val_loss: 0.7700 - val_accuracy: 0.8501\n",
      "Epoch 23/50\n",
      "97/97 [==============================] - 34s 350ms/step - loss: 1.2578 - accuracy: 0.6914 - val_loss: 0.7900 - val_accuracy: 0.8373\n",
      "Epoch 24/50\n",
      "97/97 [==============================] - 31s 322ms/step - loss: 1.2274 - accuracy: 0.7021 - val_loss: 0.7894 - val_accuracy: 0.8345\n",
      "Epoch 25/50\n",
      "97/97 [==============================] - 31s 317ms/step - loss: 1.2080 - accuracy: 0.7045 - val_loss: 0.8137 - val_accuracy: 0.8376\n",
      "Epoch 26/50\n",
      "97/97 [==============================] - 31s 318ms/step - loss: 1.1711 - accuracy: 0.7182 - val_loss: 0.7774 - val_accuracy: 0.8395\n",
      "Epoch 27/50\n",
      "97/97 [==============================] - 31s 317ms/step - loss: 1.1594 - accuracy: 0.7198 - val_loss: 0.7827 - val_accuracy: 0.8313\n",
      "Epoch 28/50\n",
      "97/97 [==============================] - 35s 364ms/step - loss: 1.1356 - accuracy: 0.7264 - val_loss: 0.7266 - val_accuracy: 0.8505\n",
      "Epoch 29/50\n",
      "97/97 [==============================] - 32s 330ms/step - loss: 1.1084 - accuracy: 0.7300 - val_loss: 0.7160 - val_accuracy: 0.8517\n",
      "Epoch 30/50\n",
      "97/97 [==============================] - 32s 330ms/step - loss: 1.0895 - accuracy: 0.7388 - val_loss: 0.6703 - val_accuracy: 0.8696\n",
      "Epoch 31/50\n",
      "97/97 [==============================] - 32s 328ms/step - loss: 1.0690 - accuracy: 0.7462 - val_loss: 0.7366 - val_accuracy: 0.8481\n",
      "Epoch 32/50\n",
      "97/97 [==============================] - 31s 317ms/step - loss: 1.0508 - accuracy: 0.7488 - val_loss: 0.6258 - val_accuracy: 0.8860\n",
      "Epoch 33/50\n",
      "97/97 [==============================] - 30s 314ms/step - loss: 1.0440 - accuracy: 0.7518 - val_loss: 0.7229 - val_accuracy: 0.8511\n",
      "Epoch 34/50\n",
      "97/97 [==============================] - 31s 324ms/step - loss: 1.0226 - accuracy: 0.7564 - val_loss: 0.6055 - val_accuracy: 0.8868\n",
      "Epoch 35/50\n",
      "97/97 [==============================] - 30s 306ms/step - loss: 1.0249 - accuracy: 0.7565 - val_loss: 0.7222 - val_accuracy: 0.8517\n",
      "Epoch 36/50\n",
      "97/97 [==============================] - 31s 317ms/step - loss: 0.9980 - accuracy: 0.7635 - val_loss: 0.6849 - val_accuracy: 0.8607\n",
      "Epoch 37/50\n",
      "97/97 [==============================] - 32s 326ms/step - loss: 0.9946 - accuracy: 0.7667 - val_loss: 0.6325 - val_accuracy: 0.8783\n",
      "Epoch 38/50\n",
      "97/97 [==============================] - 33s 345ms/step - loss: 0.9656 - accuracy: 0.7709 - val_loss: 0.6172 - val_accuracy: 0.8830\n",
      "Epoch 39/50\n",
      "97/97 [==============================] - 31s 319ms/step - loss: 0.9649 - accuracy: 0.7729 - val_loss: 0.6229 - val_accuracy: 0.8799\n",
      "Epoch 40/50\n",
      "97/97 [==============================] - 33s 344ms/step - loss: 0.9602 - accuracy: 0.7753 - val_loss: 0.6033 - val_accuracy: 0.8842\n",
      "Epoch 41/50\n",
      "97/97 [==============================] - 37s 380ms/step - loss: 0.9437 - accuracy: 0.7787 - val_loss: 0.7544 - val_accuracy: 0.8470\n",
      "Epoch 42/50\n",
      "97/97 [==============================] - 38s 394ms/step - loss: 0.9326 - accuracy: 0.7825 - val_loss: 0.5506 - val_accuracy: 0.9001\n",
      "Epoch 43/50\n",
      "97/97 [==============================] - 34s 351ms/step - loss: 0.9258 - accuracy: 0.7841 - val_loss: 0.5579 - val_accuracy: 0.8939\n",
      "Epoch 44/50\n",
      "97/97 [==============================] - 36s 366ms/step - loss: 0.9258 - accuracy: 0.7834 - val_loss: 0.5997 - val_accuracy: 0.8889\n",
      "Epoch 45/50\n",
      "97/97 [==============================] - 33s 344ms/step - loss: 0.9051 - accuracy: 0.7889 - val_loss: 0.5448 - val_accuracy: 0.9006\n",
      "Epoch 46/50\n",
      "97/97 [==============================] - 35s 360ms/step - loss: 0.9153 - accuracy: 0.7857 - val_loss: 0.6465 - val_accuracy: 0.8721\n",
      "Epoch 47/50\n",
      "97/97 [==============================] - 32s 329ms/step - loss: 0.9047 - accuracy: 0.7855 - val_loss: 0.7069 - val_accuracy: 0.8551\n",
      "Epoch 48/50\n",
      "97/97 [==============================] - 31s 318ms/step - loss: 0.8964 - accuracy: 0.7930 - val_loss: 0.6076 - val_accuracy: 0.8801\n",
      "Epoch 49/50\n",
      "97/97 [==============================] - 35s 359ms/step - loss: 0.8975 - accuracy: 0.7919 - val_loss: 0.5738 - val_accuracy: 0.8890\n",
      "Epoch 50/50\n",
      "97/97 [==============================] - 40s 409ms/step - loss: 0.8768 - accuracy: 0.7955 - val_loss: 0.5335 - val_accuracy: 0.8995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20ac758a108>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "\t  width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "\t  horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "model.fit_generator(aug.flow(X_train, y_train, batch_size=300),\n",
    "                             steps_per_epoch=len(X_train) // 300,\n",
    "                             epochs=50,\n",
    "                             validation_data=(X_test,y_test), shuffle = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model \n",
    "model.save('C:\\\\Users\\HP\\Desktop\\optical-character-recognition-OCR-master\\models\\model45.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('C:\\\\Users\\HP\\Desktop\\optical-character-recognition-OCR-master\\models/xtrain',X_train,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
